{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44fce22-310f-4768-932d-00757b9229db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24de928f-d07c-4bce-bf51-80c03739fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Iran.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(set(text))\n",
    "vocabulary_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe6f596-a949-46f1-ae4c-4ff65dcebc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string) -> list:\n",
    "    return [string_to_int[c] for c in string]\n",
    "\n",
    "def decode(l) -> str:\n",
    "    return ''.join([int_to_string[s] for s in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf69b5cf-a3d9-4e57-860a-ee171568bd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([106,  48,  65,  62,   1,  44,  75,  72,  67,  62,  60,  77,   1,  35,\n",
      "         78,  77,  62,  71,  59,  62,  75,  64,   1,  62,  30,  72,  72,  68,\n",
      "          1,  72,  63,   1,  48,  65,  62,   1,  44,  62,  75,  76,  66,  58,\n",
      "         71,   1,  40,  66,  77,  62,  75,  58,  77,  78,  75,  62,  11,   1,\n",
      "         31,  72,  70,  73,  75,  66,  76,  66,  71,  64,   1,  48,  65,  62,\n",
      "          1,  47,  65,  58,  65,   1,  42,  58,  70,  62,  65,  11,   1,  48,\n",
      "         65,  62,   1,  46,  78,  59,  58,  66,  82,  58,  77,  11,   1,  48,\n",
      "         65,  62])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch:i for i, ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f4b40e3-7b2f-424c-a544-a8351b488ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([283806, 651551, 660844, 663491])\n",
      "inputs:\n",
      "tensor([[64, 76,  1, 60, 65, 58, 75, 70],\n",
      "        [71,  1, 37,  1, 80, 58, 76,  1],\n",
      "        [71, 64,  1, 77, 65, 62,  1, 61],\n",
      "        [58, 70, 62, 28,  3,  0,  0, 54]])\n",
      "targets:\n",
      "tensor([[76,  1, 60, 65, 58, 75, 70, 62],\n",
      "        [ 1, 37,  1, 80, 58, 76,  1, 70],\n",
      "        [64,  1, 77, 65, 62,  1, 61, 62],\n",
      "        [70, 62, 28,  3,  0,  0, 54, 97]])\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a628d60d-0ddd-4536-9644-f2092ddebf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ud;‘:4,=”’d6äKg:aV*“aJTííe-gz]kfârl—3êH6‘q’ïádEMàyg—JBó•à3ükyf™C “Y3 Ud!fq!QlkO%v\n",
      "lPar3Z6H﻿s\"Gby;!riÁ]xÁ=óU9c*óâÍcâ﻿EUDDA2C(zQ“PWkC™™F8?Y‘vèU-vs2âQ]\"á6iäêy’w/ AwáT—'ïàZCNz]eRzès6áFxC/Su3wä—u c!ü”jxMúU9﻿ázctó4HPHAúÁJeA\n",
      "=fí8bBm]eq-a88[_TCNéàïou,#/prePH\n",
      "úÁê%jèy[8x-’ä8íki-âEdEUäw\n",
      "DThä(gs—QhW)9=â18?r‘:XHúÍ_wJÚ—àXNU™”3íjÁBfcÁ99êx-L2c.—J3“YEL tüqUDb#í8qmä0v) gàé‘'pi'R;55””mNäcM,3?w’‘:VncQ.qvOx9üC2WÍPKi=;‘?y’EL hiêt5%YtE—tJ4l.[*RH3yC!qüâAQhBéJ!KQ8 D“äl4.'“Yv*éA'ïóiH﻿zQcmäA2a:j]:=]7CC“,Yvdéan;èuv‘aREHb à\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        if targets is None: \n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self.forward(index)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "\n",
    "        return index\n",
    "\n",
    "model = BigramLanguageModel(vocab_size=vocabulary_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
